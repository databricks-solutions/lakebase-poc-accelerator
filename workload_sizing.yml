# Lakebase Postgres Workload Sizing Configuration
# This template collects user inputs for Postgres instance sizing and cost estimation

# Database Instance Unit Configuration
database_instance:
  # Bulk writes from Delta table for initial data loading and batch updates
  bulk_writes_per_second: 0
  
  # Continuous writes from Delta table for real-time order processing
  continuous_writes_per_second: 0
  
  # Read operations for customer lookups, product searches
  reads_per_second: 0
  
  # Read replicas for analytics and reporting
  number_of_readable_secondaries: 0
  readable_secondary_size_cu: 1

  # Lakebase Promotion percentage (0-100)
  promotion_percentage: 50.0

# Database Storage Configuration
database_storage:
  # Total data size including all tables and indexes
  data_stored_gb: 0
  
  # Daily data cleanup 
  estimated_data_deleted_daily_gb: 0

  # Restore windows for data recovery (days)
  restore_windows_days: 0

# Delta Synchronization Configuration
delta_synchronization:
  # Real-time sync for critical data
  number_of_continuous_pipelines: 0
  
  # Batch sync for analytics data
  expected_data_per_sync_gb: 0
  
  # Use snapshot for consistent analytics
  sync_mode: "Snapshot"
  
  # Run analytics sync daily
  sync_frequency: "Per day"

# Example configurations for different workload types

# Example 1: Light OLTP Workload
# database_instance:
#   bulk_writes_per_second: 1000
#   continuous_writes_per_second: 500
#   reads_per_second: 2000
#   number_of_readable_secondaries: 0
#   readable_secondary_size_cu: 1
#   promotion_percentage: 0.0
# 
# database_storage:
#   data_stored_gb: 50
#   estimated_data_deleted_daily_gb: 1
#   restore_windows_days: 3
# 
# delta_synchronization:
#   number_of_continuous_pipelines: 1
#   expected_data_per_sync_gb: 5
#   sync_mode: "Snapshot"
#   sync_frequency: "Per day"

# Example 2: Heavy Analytics Workload
# database_instance:
#   bulk_writes_per_second: 10000
#   continuous_writes_per_second: 2000
#   reads_per_second: 5000
#   number_of_readable_secondaries: 2
#   readable_secondary_size_cu: 2
#   promotion_percentage: 25.0
# 
# database_storage:
#   data_stored_gb: 500
#   estimated_data_deleted_daily_gb: 10
#   restore_windows_days: 14
# 
# delta_synchronization:
#   number_of_continuous_pipelines: 3
#   expected_data_per_sync_gb: 50
#   sync_mode: "Triggered"
#   sync_frequency: "Per hour"

# Example 3: Enterprise Production Workload
# database_instance:
#   bulk_writes_per_second: 50000
#   continuous_writes_per_second: 10000
#   reads_per_second: 20000
#   number_of_readable_secondaries: 3
#   readable_secondary_size_cu: 4
#   promotion_percentage: 50.0
# 
# database_storage:
#   data_stored_gb: 2000
#   estimated_data_deleted_daily_gb: 50
#   restore_windows_days: 30
# 
# delta_synchronization:
#   number_of_continuous_pipelines: 5
#   expected_data_per_sync_gb: 100
#   sync_mode: "Snapshot"
#   sync_frequency: "Per day"