# Example Lakebase Postgres Workload Configuration
# This is an example configuration for a medium-sized e-commerce application

# Database Instance Unit Configuration
database_instance:
  # Bulk writes for initial data loading and batch updates
  bulk_writes_per_second: 5000
  
  # Continuous writes for real-time order processing
  continuous_writes_per_second: 2000
  
  # Read operations for customer lookups, product searches
  reads_per_second: 8000
  
  # Read replicas for analytics and reporting
  number_of_readable_secondaries: 2
  readable_secondary_size_cu: 2

  # Lakebase Promotion percentage
  promotion_percentage: 50.0

# Database Storage Configuration
database_storage:
  # Total data size including all tables and indexes
  data_stored_gb: 250
  
  # Daily data cleanup (archived orders, expired sessions)
  estimated_data_deleted_daily_gb: 5
  
  # Restore windows for data recovery (days)
  restore_windows_days: 7

# Delta Synchronization Configuration
delta_synchronization:
  # Real-time sync for critical data
  number_of_continuous_pipelines: 2
  
  # Batch sync for analytics data
  expected_data_per_sync_gb: 20
  
  # Use snapshot for consistent analytics
  sync_mode: "Triggered"
  
  # Run analytics sync daily
  sync_frequency: "Per day"
